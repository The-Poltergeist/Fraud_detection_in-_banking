{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65521ff",
   "metadata": {},
   "source": [
    "# Enoch Samuel Bonthu, 1905317, KIIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81943b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7445e60",
   "metadata": {},
   "source": [
    "## checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28407972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Fraud.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d95bac",
   "metadata": {},
   "source": [
    "### we drop the nameOrig and nameDest columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42177a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['nameOrig','nameDest'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6182b3b",
   "metadata": {},
   "source": [
    "### checking na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d3e933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step              0\n",
       "type              0\n",
       "amount            0\n",
       "oldbalanceOrg     0\n",
       "newbalanceOrig    0\n",
       "oldbalanceDest    0\n",
       "newbalanceDest    0\n",
       "isFraud           0\n",
       "isFlaggedFraud    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ff274",
   "metadata": {},
   "source": [
    "### Cheking last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3e239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6362604\n",
       "1         16\n",
       "Name: isFlaggedFraud, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b84e9",
   "metadata": {},
   "source": [
    "### checking multi-collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bca7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_77ac7_row0_col0, #T_77ac7_row1_col1, #T_77ac7_row2_col2, #T_77ac7_row2_col3, #T_77ac7_row3_col2, #T_77ac7_row3_col3, #T_77ac7_row4_col4, #T_77ac7_row5_col5, #T_77ac7_row6_col6, #T_77ac7_row7_col7 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row0_col1 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row0_col2, #T_77ac7_row0_col3, #T_77ac7_row0_col7, #T_77ac7_row1_col3, #T_77ac7_row2_col0, #T_77ac7_row3_col0, #T_77ac7_row3_col1, #T_77ac7_row3_col6, #T_77ac7_row4_col6, #T_77ac7_row4_col7, #T_77ac7_row5_col7, #T_77ac7_row6_col3, #T_77ac7_row6_col4, #T_77ac7_row6_col5, #T_77ac7_row7_col5 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row0_col4, #T_77ac7_row1_col0 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row0_col5 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row0_col6, #T_77ac7_row2_col5, #T_77ac7_row3_col5, #T_77ac7_row6_col0 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row1_col2, #T_77ac7_row2_col1, #T_77ac7_row2_col7, #T_77ac7_row3_col7, #T_77ac7_row7_col4 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row1_col4, #T_77ac7_row4_col1 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77ac7_row1_col5 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77ac7_row1_col6, #T_77ac7_row6_col1 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row1_col7, #T_77ac7_row7_col0, #T_77ac7_row7_col2, #T_77ac7_row7_col3 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row2_col4, #T_77ac7_row3_col4 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row2_col6 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row4_col0, #T_77ac7_row5_col0 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row4_col2, #T_77ac7_row4_col3 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row4_col5, #T_77ac7_row5_col4 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row5_col1 {\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77ac7_row5_col2, #T_77ac7_row5_col3, #T_77ac7_row7_col6 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row5_col6 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row6_col2, #T_77ac7_row7_col1 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77ac7_row6_col7 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_77ac7_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >step</th>\n",
       "      <th class=\"col_heading level0 col1\" >amount</th>\n",
       "      <th class=\"col_heading level0 col2\" >oldbalanceOrg</th>\n",
       "      <th class=\"col_heading level0 col3\" >newbalanceOrig</th>\n",
       "      <th class=\"col_heading level0 col4\" >oldbalanceDest</th>\n",
       "      <th class=\"col_heading level0 col5\" >newbalanceDest</th>\n",
       "      <th class=\"col_heading level0 col6\" >isFraud</th>\n",
       "      <th class=\"col_heading level0 col7\" >isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row0\" class=\"row_heading level0 row0\" >step</th>\n",
       "      <td id=\"T_77ac7_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_77ac7_row0_col1\" class=\"data row0 col1\" >0.022373</td>\n",
       "      <td id=\"T_77ac7_row0_col2\" class=\"data row0 col2\" >-0.010058</td>\n",
       "      <td id=\"T_77ac7_row0_col3\" class=\"data row0 col3\" >-0.010299</td>\n",
       "      <td id=\"T_77ac7_row0_col4\" class=\"data row0 col4\" >0.027665</td>\n",
       "      <td id=\"T_77ac7_row0_col5\" class=\"data row0 col5\" >0.025888</td>\n",
       "      <td id=\"T_77ac7_row0_col6\" class=\"data row0 col6\" >0.031578</td>\n",
       "      <td id=\"T_77ac7_row0_col7\" class=\"data row0 col7\" >0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row1\" class=\"row_heading level0 row1\" >amount</th>\n",
       "      <td id=\"T_77ac7_row1_col0\" class=\"data row1 col0\" >0.022373</td>\n",
       "      <td id=\"T_77ac7_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_77ac7_row1_col2\" class=\"data row1 col2\" >-0.002762</td>\n",
       "      <td id=\"T_77ac7_row1_col3\" class=\"data row1 col3\" >-0.007861</td>\n",
       "      <td id=\"T_77ac7_row1_col4\" class=\"data row1 col4\" >0.294137</td>\n",
       "      <td id=\"T_77ac7_row1_col5\" class=\"data row1 col5\" >0.459304</td>\n",
       "      <td id=\"T_77ac7_row1_col6\" class=\"data row1 col6\" >0.076688</td>\n",
       "      <td id=\"T_77ac7_row1_col7\" class=\"data row1 col7\" >0.012295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row2\" class=\"row_heading level0 row2\" >oldbalanceOrg</th>\n",
       "      <td id=\"T_77ac7_row2_col0\" class=\"data row2 col0\" >-0.010058</td>\n",
       "      <td id=\"T_77ac7_row2_col1\" class=\"data row2 col1\" >-0.002762</td>\n",
       "      <td id=\"T_77ac7_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_77ac7_row2_col3\" class=\"data row2 col3\" >0.998803</td>\n",
       "      <td id=\"T_77ac7_row2_col4\" class=\"data row2 col4\" >0.066243</td>\n",
       "      <td id=\"T_77ac7_row2_col5\" class=\"data row2 col5\" >0.042029</td>\n",
       "      <td id=\"T_77ac7_row2_col6\" class=\"data row2 col6\" >0.010154</td>\n",
       "      <td id=\"T_77ac7_row2_col7\" class=\"data row2 col7\" >0.003835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row3\" class=\"row_heading level0 row3\" >newbalanceOrig</th>\n",
       "      <td id=\"T_77ac7_row3_col0\" class=\"data row3 col0\" >-0.010299</td>\n",
       "      <td id=\"T_77ac7_row3_col1\" class=\"data row3 col1\" >-0.007861</td>\n",
       "      <td id=\"T_77ac7_row3_col2\" class=\"data row3 col2\" >0.998803</td>\n",
       "      <td id=\"T_77ac7_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_77ac7_row3_col4\" class=\"data row3 col4\" >0.067812</td>\n",
       "      <td id=\"T_77ac7_row3_col5\" class=\"data row3 col5\" >0.041837</td>\n",
       "      <td id=\"T_77ac7_row3_col6\" class=\"data row3 col6\" >-0.008148</td>\n",
       "      <td id=\"T_77ac7_row3_col7\" class=\"data row3 col7\" >0.003776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row4\" class=\"row_heading level0 row4\" >oldbalanceDest</th>\n",
       "      <td id=\"T_77ac7_row4_col0\" class=\"data row4 col0\" >0.027665</td>\n",
       "      <td id=\"T_77ac7_row4_col1\" class=\"data row4 col1\" >0.294137</td>\n",
       "      <td id=\"T_77ac7_row4_col2\" class=\"data row4 col2\" >0.066243</td>\n",
       "      <td id=\"T_77ac7_row4_col3\" class=\"data row4 col3\" >0.067812</td>\n",
       "      <td id=\"T_77ac7_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_77ac7_row4_col5\" class=\"data row4 col5\" >0.976569</td>\n",
       "      <td id=\"T_77ac7_row4_col6\" class=\"data row4 col6\" >-0.005885</td>\n",
       "      <td id=\"T_77ac7_row4_col7\" class=\"data row4 col7\" >-0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row5\" class=\"row_heading level0 row5\" >newbalanceDest</th>\n",
       "      <td id=\"T_77ac7_row5_col0\" class=\"data row5 col0\" >0.025888</td>\n",
       "      <td id=\"T_77ac7_row5_col1\" class=\"data row5 col1\" >0.459304</td>\n",
       "      <td id=\"T_77ac7_row5_col2\" class=\"data row5 col2\" >0.042029</td>\n",
       "      <td id=\"T_77ac7_row5_col3\" class=\"data row5 col3\" >0.041837</td>\n",
       "      <td id=\"T_77ac7_row5_col4\" class=\"data row5 col4\" >0.976569</td>\n",
       "      <td id=\"T_77ac7_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_77ac7_row5_col6\" class=\"data row5 col6\" >0.000535</td>\n",
       "      <td id=\"T_77ac7_row5_col7\" class=\"data row5 col7\" >-0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row6\" class=\"row_heading level0 row6\" >isFraud</th>\n",
       "      <td id=\"T_77ac7_row6_col0\" class=\"data row6 col0\" >0.031578</td>\n",
       "      <td id=\"T_77ac7_row6_col1\" class=\"data row6 col1\" >0.076688</td>\n",
       "      <td id=\"T_77ac7_row6_col2\" class=\"data row6 col2\" >0.010154</td>\n",
       "      <td id=\"T_77ac7_row6_col3\" class=\"data row6 col3\" >-0.008148</td>\n",
       "      <td id=\"T_77ac7_row6_col4\" class=\"data row6 col4\" >-0.005885</td>\n",
       "      <td id=\"T_77ac7_row6_col5\" class=\"data row6 col5\" >0.000535</td>\n",
       "      <td id=\"T_77ac7_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_77ac7_row6_col7\" class=\"data row6 col7\" >0.044109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77ac7_level0_row7\" class=\"row_heading level0 row7\" >isFlaggedFraud</th>\n",
       "      <td id=\"T_77ac7_row7_col0\" class=\"data row7 col0\" >0.003277</td>\n",
       "      <td id=\"T_77ac7_row7_col1\" class=\"data row7 col1\" >0.012295</td>\n",
       "      <td id=\"T_77ac7_row7_col2\" class=\"data row7 col2\" >0.003835</td>\n",
       "      <td id=\"T_77ac7_row7_col3\" class=\"data row7 col3\" >0.003776</td>\n",
       "      <td id=\"T_77ac7_row7_col4\" class=\"data row7 col4\" >-0.000513</td>\n",
       "      <td id=\"T_77ac7_row7_col5\" class=\"data row7 col5\" >-0.000529</td>\n",
       "      <td id=\"T_77ac7_row7_col6\" class=\"data row7 col6\" >0.044109</td>\n",
       "      <td id=\"T_77ac7_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e31e4c6fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=data.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372cf79",
   "metadata": {},
   "source": [
    "### Finding that the data is skewed and plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a725eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6354407\n",
       "1       8213\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1286d24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(data['isFraud'])\n",
    "g.set_xticklabels(['Not Fraud','Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaacd86",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a7a3382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step      type      amount  oldbalanceOrg  newbalanceOrig  \\\n",
      "0           1   PAYMENT     9839.64      170136.00       160296.36   \n",
      "1           1   PAYMENT     1864.28       21249.00        19384.72   \n",
      "2           1  TRANSFER      181.00         181.00            0.00   \n",
      "3           1  CASH_OUT      181.00         181.00            0.00   \n",
      "4           1   PAYMENT    11668.14       41554.00        29885.86   \n",
      "...       ...       ...         ...            ...             ...   \n",
      "6362615   743  CASH_OUT   339682.13      339682.13            0.00   \n",
      "6362616   743  TRANSFER  6311409.28     6311409.28            0.00   \n",
      "6362617   743  CASH_OUT  6311409.28     6311409.28            0.00   \n",
      "6362618   743  TRANSFER   850002.52      850002.52            0.00   \n",
      "6362619   743  CASH_OUT   850002.52      850002.52            0.00   \n",
      "\n",
      "         oldbalanceDest  newbalanceDest  \n",
      "0                  0.00            0.00  \n",
      "1                  0.00            0.00  \n",
      "2                  0.00            0.00  \n",
      "3              21182.00            0.00  \n",
      "4                  0.00            0.00  \n",
      "...                 ...             ...  \n",
      "6362615            0.00       339682.13  \n",
      "6362616            0.00            0.00  \n",
      "6362617        68488.84      6379898.11  \n",
      "6362618            0.00            0.00  \n",
      "6362619      6510099.11      7360101.63  \n",
      "\n",
      "[6362620 rows x 7 columns]\n",
      "0          0\n",
      "1          0\n",
      "2          1\n",
      "3          1\n",
      "4          0\n",
      "          ..\n",
      "6362615    1\n",
      "6362616    1\n",
      "6362617    1\n",
      "6362618    1\n",
      "6362619    1\n",
      "Name: isFraud, Length: 6362620, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,:-2]#.values\n",
    "Y = data.iloc[:,-2]#.values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e21aee",
   "metadata": {},
   "source": [
    "### using VIF to check multi-collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d1166a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step</td>\n",
       "      <td>1.188495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amount</td>\n",
       "      <td>4.011315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldbalanceOrg</td>\n",
       "      <td>465.122355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newbalanceOrig</td>\n",
       "      <td>466.903890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oldbalanceDest</td>\n",
       "      <td>71.765327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>newbalanceDest</td>\n",
       "      <td>83.231611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variables         VIF\n",
       "0            step    1.188495\n",
       "1          amount    4.011315\n",
       "2   oldbalanceOrg  465.122355\n",
       "3  newbalanceOrig  466.903890\n",
       "4  oldbalanceDest   71.765327\n",
       "5  newbalanceDest   83.231611"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "def calc_vif(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return(vif)\n",
    "calc_vif(X.loc[:,X.columns!= 'type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72feb961",
   "metadata": {},
   "source": [
    "### Since the data is heavily skewed, we use undersampling to make the data balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be238942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 8213, 1: 8213})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "rus = RandomUnderSampler() \n",
    "X, Y = rus.fit_resample(X, Y)\n",
    "print(Counter(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982abd7",
   "metadata": {},
   "source": [
    "### Applying one hot encoder to the column \"type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a99a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "770c26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79cf56f",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d84fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3b062",
   "metadata": {},
   "source": [
    "### Applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af2bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_val = pca.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c679b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.23329434e-01 1.91963674e-01 1.50223908e-01 1.11689633e-01\n",
      " 9.79130781e-02 9.11518692e-02 7.86551973e-02 4.89823976e-02\n",
      " 5.52967449e-03 5.61135299e-04 6.22160317e-31]\n",
      "[0.22332943 0.41529311 0.56551702 0.67720665 0.77511973 0.8662716\n",
      " 0.94492679 0.99390919 0.99943886 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbe574",
   "metadata": {},
   "source": [
    "## Building the artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4104c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 3ms/step - loss: 0.5997 - accuracy: 0.7257 - val_loss: 0.5173 - val_accuracy: 0.7930\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8251 - val_loss: 0.3930 - val_accuracy: 0.8128\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8479 - val_loss: 0.3398 - val_accuracy: 0.8341\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8596 - val_loss: 0.3073 - val_accuracy: 0.8505\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8731 - val_loss: 0.2846 - val_accuracy: 0.8607\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8836 - val_loss: 0.2656 - val_accuracy: 0.8767\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.8930 - val_loss: 0.2499 - val_accuracy: 0.8866\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9027 - val_loss: 0.2406 - val_accuracy: 0.8896\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9083 - val_loss: 0.2242 - val_accuracy: 0.9064\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9164 - val_loss: 0.2153 - val_accuracy: 0.9136\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9198 - val_loss: 0.2063 - val_accuracy: 0.9212\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9256 - val_loss: 0.1995 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9272 - val_loss: 0.1952 - val_accuracy: 0.9140\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9283 - val_loss: 0.1873 - val_accuracy: 0.9193\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9291 - val_loss: 0.1823 - val_accuracy: 0.9266\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9330 - val_loss: 0.1760 - val_accuracy: 0.9247\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9350 - val_loss: 0.1748 - val_accuracy: 0.9224\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9356 - val_loss: 0.1687 - val_accuracy: 0.9266\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9373 - val_loss: 0.1642 - val_accuracy: 0.9281\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9385 - val_loss: 0.1597 - val_accuracy: 0.9292\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9401 - val_loss: 0.1572 - val_accuracy: 0.9338\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9418 - val_loss: 0.1528 - val_accuracy: 0.9357\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9442 - val_loss: 0.1500 - val_accuracy: 0.9395\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9448 - val_loss: 0.1482 - val_accuracy: 0.9414\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9463 - val_loss: 0.1456 - val_accuracy: 0.9406\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9471 - val_loss: 0.1459 - val_accuracy: 0.9357\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9482 - val_loss: 0.1438 - val_accuracy: 0.9395\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9473 - val_loss: 0.1439 - val_accuracy: 0.9452\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9504 - val_loss: 0.1399 - val_accuracy: 0.9429\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9506 - val_loss: 0.1464 - val_accuracy: 0.9368\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9499 - val_loss: 0.1358 - val_accuracy: 0.9429\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9516 - val_loss: 0.1369 - val_accuracy: 0.9418\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9527 - val_loss: 0.1338 - val_accuracy: 0.9479\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9542 - val_loss: 0.1426 - val_accuracy: 0.9365\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9526 - val_loss: 0.1343 - val_accuracy: 0.9498\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9542 - val_loss: 0.1301 - val_accuracy: 0.9463\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9547 - val_loss: 0.1292 - val_accuracy: 0.9509\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9549 - val_loss: 0.1304 - val_accuracy: 0.9486\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9559 - val_loss: 0.1282 - val_accuracy: 0.9509\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9567 - val_loss: 0.1274 - val_accuracy: 0.9521\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9576 - val_loss: 0.1283 - val_accuracy: 0.9505\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9580 - val_loss: 0.1252 - val_accuracy: 0.9502\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9590 - val_loss: 0.1267 - val_accuracy: 0.9505\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9583 - val_loss: 0.1287 - val_accuracy: 0.9475\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9599 - val_loss: 0.1196 - val_accuracy: 0.9570\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.1217 - val_accuracy: 0.9570\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9596 - val_loss: 0.1260 - val_accuracy: 0.9547\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9618 - val_loss: 0.1174 - val_accuracy: 0.9589\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9608 - val_loss: 0.1302 - val_accuracy: 0.9566\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9623 - val_loss: 0.1198 - val_accuracy: 0.9616\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9632 - val_loss: 0.1213 - val_accuracy: 0.9619\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9631 - val_loss: 0.1159 - val_accuracy: 0.9623\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9649 - val_loss: 0.1145 - val_accuracy: 0.9639\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9625 - val_loss: 0.1147 - val_accuracy: 0.9616\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9636 - val_loss: 0.1137 - val_accuracy: 0.9597\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9649 - val_loss: 0.1111 - val_accuracy: 0.9612\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9651 - val_loss: 0.1132 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9648 - val_loss: 0.1146 - val_accuracy: 0.9585\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9651 - val_loss: 0.1140 - val_accuracy: 0.9589\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9658 - val_loss: 0.1095 - val_accuracy: 0.9646\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9670 - val_loss: 0.1086 - val_accuracy: 0.9635\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9665 - val_loss: 0.1099 - val_accuracy: 0.9658\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9673 - val_loss: 0.1091 - val_accuracy: 0.9654\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9680 - val_loss: 0.1069 - val_accuracy: 0.9665\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9680 - val_loss: 0.1090 - val_accuracy: 0.9642\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9684 - val_loss: 0.1048 - val_accuracy: 0.9658\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9690 - val_loss: 0.1080 - val_accuracy: 0.9600\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9691 - val_loss: 0.1109 - val_accuracy: 0.9612\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9704 - val_loss: 0.1097 - val_accuracy: 0.9612\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9700 - val_loss: 0.1077 - val_accuracy: 0.9673\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9702 - val_loss: 0.1034 - val_accuracy: 0.9669\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9706 - val_loss: 0.1031 - val_accuracy: 0.9715\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9724 - val_loss: 0.1032 - val_accuracy: 0.9692\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9724 - val_loss: 0.1029 - val_accuracy: 0.9730\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9712 - val_loss: 0.1074 - val_accuracy: 0.9718\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9723 - val_loss: 0.1061 - val_accuracy: 0.9692\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9730 - val_loss: 0.1033 - val_accuracy: 0.9737\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9729 - val_loss: 0.1041 - val_accuracy: 0.9737\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9732 - val_loss: 0.1112 - val_accuracy: 0.9677\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9742 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9751 - val_loss: 0.0982 - val_accuracy: 0.9737\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9736 - val_loss: 0.1051 - val_accuracy: 0.9623\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9734 - val_loss: 0.1034 - val_accuracy: 0.9692\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9756 - val_loss: 0.0995 - val_accuracy: 0.9718\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9739 - val_loss: 0.1026 - val_accuracy: 0.9665\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9750 - val_loss: 0.0970 - val_accuracy: 0.9741\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9763 - val_loss: 0.1103 - val_accuracy: 0.9593\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9752 - val_loss: 0.0996 - val_accuracy: 0.9703\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9765 - val_loss: 0.0964 - val_accuracy: 0.9745\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9767 - val_loss: 0.0963 - val_accuracy: 0.9741\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9762 - val_loss: 0.0941 - val_accuracy: 0.9745\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9755 - val_loss: 0.0947 - val_accuracy: 0.9764\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9764 - val_loss: 0.0929 - val_accuracy: 0.9749\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9758 - val_loss: 0.0973 - val_accuracy: 0.9741\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9774 - val_loss: 0.0964 - val_accuracy: 0.9753\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9773 - val_loss: 0.0924 - val_accuracy: 0.9772\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9787 - val_loss: 0.1029 - val_accuracy: 0.9677\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9771 - val_loss: 0.0950 - val_accuracy: 0.9730\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9780 - val_loss: 0.1066 - val_accuracy: 0.9692\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9764 - val_loss: 0.0915 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e383a15100>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=11, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann.fit(X_train, y_train, batch_size = 100, epochs = 100,validation_data = (X_val,y_val))#,validation_steps = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baad633",
   "metadata": {},
   "source": [
    "### Predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0e6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f43660",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c48322",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1582   48]\n",
      " [  30 1626]]\n",
      "0.9762629336579428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(cm)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "043e706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step      type      amount  oldbalanceOrg  newbalanceOrig  \\\n",
      "2           1  TRANSFER      181.00         181.00             0.0   \n",
      "3           1  CASH_OUT      181.00         181.00             0.0   \n",
      "251         1  TRANSFER     2806.00        2806.00             0.0   \n",
      "252         1  CASH_OUT     2806.00        2806.00             0.0   \n",
      "680         1  TRANSFER    20128.00       20128.00             0.0   \n",
      "...       ...       ...         ...            ...             ...   \n",
      "6362615   743  CASH_OUT   339682.13      339682.13             0.0   \n",
      "6362616   743  TRANSFER  6311409.28     6311409.28             0.0   \n",
      "6362617   743  CASH_OUT  6311409.28     6311409.28             0.0   \n",
      "6362618   743  TRANSFER   850002.52      850002.52             0.0   \n",
      "6362619   743  CASH_OUT   850002.52      850002.52             0.0   \n",
      "\n",
      "         oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "2                  0.00            0.00        1               0  \n",
      "3              21182.00            0.00        1               0  \n",
      "251                0.00            0.00        1               0  \n",
      "252            26202.00            0.00        1               0  \n",
      "680                0.00            0.00        1               0  \n",
      "...                 ...             ...      ...             ...  \n",
      "6362615            0.00       339682.13        1               0  \n",
      "6362616            0.00            0.00        1               0  \n",
      "6362617        68488.84      6379898.11        1               0  \n",
      "6362618            0.00            0.00        1               0  \n",
      "6362619      6510099.11      7360101.63        1               0  \n",
      "\n",
      "[8213 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[data['isFraud']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc370cb",
   "metadata": {},
   "source": [
    "1. Data cleaning including missing values, outliers and multi-collinearity. \n",
    "   \n",
    "   As we checked there were no missing values in the dataset. We checked collinearity by using two methods -  the corr function and VIF function. We find that 'oldbalanceOrg' and 'newbalanceOrig' are highly collinear. We apply PCA to tackle this. We then check 'using pca.explained_variance_ratio_' function to verify if features are multi-collinear or not.\n",
    "    \n",
    "    \n",
    "2. Describe your fraud detection model in elaboration.\n",
    "    \n",
    "    So first we read the file and then check the columns which are relevant. we drop both 'nameOrig' and 'nameDest'. We then check the last column. Since it is pretty skewed we drop that too. We then check for collinerity using the above strategy. We also realise that the data itself is pretty skewed. We tackle this using the method of undersampling to balance it. we apply one hot encoder to the 'type' column. After that we divide the data set into Train, Validation and Test. We then use other pre processing steps like scaling the columns and applying PCA. We then feed the training set into the Artificial Neural Network and let it calculate the weights and cross verify it with the cross validation set. We then predict using the test set and print the prediction metric using confusion matrix and accuracy.\n",
    "    \n",
    "    \n",
    "3. How did you select variables to be included in the model?\n",
    "    \n",
    "    We drop both 'nameOrig' and 'nameDest' because they arent relevant to the dataset. we then check the last column and find its skewed and drop that too. We then check for collinearity and deicide whether to drop the columns or apply PCA to it. We use PCA.\n",
    "    \n",
    "    \n",
    "4. Demonstrate the performance of the model by using best set of tools.\n",
    "    \n",
    "    The model is evaluated using the confusion matrix and accuracy as show above.\n",
    "\n",
    "\n",
    "5. What are the key factors that predict fraudulent customer?\n",
    "   \n",
    "   The 'type' and 'amount' play major roles in predicting fradulant customers.\n",
    "    \n",
    "    \n",
    "6. Do these factors make sense? If yes, How? If not, How not?\n",
    "    \n",
    "    Yes, these factors do make sense. As most of the cases of frad as seen above is of the type - 'CASH_OUT' and 'TRANSFER'. Similarly we can see the trend for amount where there is a drastic change in most of the cases.\n",
    "    \n",
    "\n",
    "7. What kind of prevention should be adopted while company update its infrastructure?\n",
    "\n",
    "    The company can thoroughly check when a user decided to cash out or when any large amount is being transferred. There should implement a limit where the user can't transfer more funds above that limit.\n",
    "    \n",
    "\n",
    "8. Assuming these actions have been implemented, how would you determine if they work?\n",
    "\n",
    "    By keeping a regular check on the accounts which are transferring funds, improving security, two factor authentication can be implemented. They should also keep a close check when a person decided to cash out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa3948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
